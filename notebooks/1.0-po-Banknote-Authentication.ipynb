{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83ab741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup project root and import config\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Define project root and append to sys.path\n",
    "#PROJ_ROOT = Path(__file__).resolve().parents[1]\n",
    "PROJ_ROOT = Path().resolve().parent\n",
    "print(PROJ_ROOT)\n",
    "sys.path.append(str(PROJ_ROOT))\n",
    "\n",
    "# Now import config\n",
    "from banknote_auth import config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6604e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned dataset\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(config.PROCESSED_DATA_DIR / \"data_cleaned.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af379eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "import joblib\n",
    "\n",
    "model = joblib.load(config.MODELS_DIR / \"best_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6785cf06-8deb-4111-88ed-4a31e4a3cc4f",
   "metadata": {},
   "source": [
    "## 📘 Project Outline: Banknote Authentication using Machine Learning\n",
    "\n",
    ">*Click on any section to jump to that part of the notebook.*\n",
    "\n",
    "1. [Import Required Libraries](#1.-Import-Required-Libraries)  \n",
    "2. [Problem Statement](#2.-Problem-Statement)\n",
    "3. [Project Structure](#3.-Project-Structure)  \n",
    "4. [Dataset Overview](#4.-Dataset-Overview)  \n",
    "5. [Exploratory Data Analysis (EDA)](#5.-Exploratory-Data-Analysis-(EDA))  \n",
    "     5.1 [EDA Summary](#5.1-EDA-Summary)\n",
    "6. [Feature Engineering](#6.-Feature-Engineering)  \n",
    "     6.1 [Define Dependent and Independent Variables](#6.1-Define-Dependent-and-Independent-Variables)  \n",
    "     6.2 [Data Preprocessing](#6.2-Data-Preprocessing)  \n",
    "     6.3 [Train-Test Split](#6.3-Train-Test-Split)\n",
    "7. [Model Training and Evaluation](#7.-Model-Training-and-Evaluation)  \n",
    "     7.1 [Logistic Regression](#7.1-Logistic-Regression)  \n",
    "     7.2 [K-Nearest Neighbors (KNN)](#7.2-K-Nearest-Neighbors-(KNN))  \n",
    "     7.3 [Support Vector Machine (SVM)](#7.3-Support-Vector-Machine-(SVM))  \n",
    "     7.4 [Decision Tree](#7.4-Decision-Tree)  \n",
    "     7.5 [Random Forest](#7.5-Random-Forest)  \n",
    "     7.6 [XGBoost](#7.6-XGBoost)\n",
    "8. [Model Comparison and Evaluation](#8.-Model-Comparison-and-Evaluation)  \n",
    "     8.1 [Performance Metrics](#8.1-Performance-Metrics)  \n",
    "     8.2 [Overfitting Check](#8.2-Overfitting-Check)  \n",
    "     8.3 [Visualize Model Scores](#8.3-Visualize-Model-Scores)  \n",
    "     8.4 [Model Comparison Train and Test Accuracy](#8.4-Model-Comparison-Train-and-Test-Accuracy)\n",
    "9. [Hyperparameter Tuning (Top Models)](#9.-Hyperparameter-Tuning-(Top-Models))  \n",
    "     9.1 [GridSearchCV for SVM](#9.1-GridSearchCV-for-SVM)  \n",
    "     9.2 [GridSearchCV for KNN](#9.2-GridSearchCV-for-KNN)  \n",
    "     9.3 [GridSearchCV for Random Forest](#9.3-GridSearchCV-for-Random-Forest)  \n",
    "     9.4 [GridSearchCV for XGBoost](#9.4-GridSearchCV-for-XGBoost)\n",
    "10. [Ensemble Learning](#10.-Ensemble-Learning)  \n",
    "     10.1 [VotingClassifier](#10.1-VotingClassifier)  \n",
    "     10.2 [Evaluation of Ensemble Model](#10.2-Evaluation-of-Ensemble-Model)  \n",
    "     10.3 [Confusion Matrix and ROC Curve](#10.3-Confusion-Matrix-and-ROC-Curve)\n",
    "11. [Save trained Models](#11.-Save-Trained-Models)\n",
    "    11.1 [Save Scaler](#11.1-Save-Scaler)\n",
    "    11.2 [Load Saved Trained Model and Make Prediction](#11.2-Load-Saved-Trained-Model-and-Make-Prediction)\n",
    "12. [Deployment (Optional)](#12.-Deployment-(Optional))  \n",
    "13. [Conclusion](#13.-Conclusion)  \n",
    "14. [Results](#14.-Results)\n",
    "15. [References](#14.-References)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79051066-2da0-4cc9-b967-f2a36c3e43d2",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd0aa23-5fa8-4109-8c25-e69803d2809e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install missingno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895aac79-c177-4621-873b-f2dccb984e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import missingno as msno\n",
    "from scipy import stats\n",
    "from scipy.stats import sem\n",
    "from scipy.stats import skew\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"]=(8, 6)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692fd224-6370-4c42-8bcc-b17b80134fc0",
   "metadata": {},
   "source": [
    "## 2. Problem Statement\n",
    "\n",
    "#### Banknote Authentication with Machine Learning: Financial Fraud Detection Through Image Analysis\n",
    "\n",
    "This dataset addresses a critical challenge in financial security: automated detection of counterfeit banknotes. Comprising 1,372 analyzed samples derived from 400×400 pixel images of genuine and forged currency, it provides a clean, ready-to-use resource for binary classification with:\n",
    "\n",
    "* No missing values\n",
    "* Wavelet-transformed features (mathematically robust for texture analysis)\n",
    "* Clear class labels (0 = genuine, 1 = forged)\n",
    "\n",
    "Key Features Extracted via Wavelet Transform:\n",
    "\n",
    "- Variance - Measures dispersion in transformed image texture\n",
    "\n",
    "- Skewness - Quantifies asymmetry in pixel intensity distribution\n",
    "\n",
    "- Curtosis - Detects unusual patterns in image sharpness\n",
    "\n",
    "- Entropy - Assesses randomness in visual patterns\n",
    "\n",
    "Learning Opportunities:\n",
    "\n",
    "* Benchmark classification algorithms (Logistic Regression → XGBoost)\n",
    "* Investigate feature importance for anti-counterfeiting systems\n",
    "* Validate wavelet transforms for financial image processing\n",
    "* Develop deployable fraud detection models\n",
    "\n",
    "#### Business Impact:\n",
    "\n",
    "* ATM/Cash-Handling Integration: Potential deployment in ATMs, vending machines, and bank counters to block counterfeit notes in real time.\n",
    "\n",
    "* Cost Reduction: Minimizes losses from fraud while reducing manual verification overhead.\n",
    "\n",
    "\n",
    "Source: UCI Machine Learning Repository (Donor: Helene Dörksen, University of Applied Sciences, Ostwestfalen-Lippe).\n",
    "\n",
    "Dataset link:https://www.kaggle.com/datasets/shantanuss/banknote-authentication-uci?resource=download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3041445-7297-421a-9a3e-b88972235a28",
   "metadata": {},
   "source": [
    "## 3. Project Structure\n",
    "\n",
    "```\n",
    "├── LICENSE            <- Open-source license if one is chosen\n",
    "├── Makefile           <- Makefile with convenience commands like `make data` or `make train`\n",
    "├── README.md          <- The top-level README for developers using this project.\n",
    "├── data\n",
    "│   ├── external       <- Data from third party sources.\n",
    "│   ├── interim        <- Intermediate data that has been transformed.\n",
    "│   ├── processed      <- The final, canonical data sets for modeling.\n",
    "│   └── raw            <- The original, immutable data dump.\n",
    "│\n",
    "├── docs               <- A default mkdocs project; see www.mkdocs.org for details\n",
    "│\n",
    "├── models             <- Trained and serialized models, model predictions, or model summaries\n",
    "│\n",
    "├── notebooks          <- Jupyter notebooks. Naming convention is a number (for ordering),\n",
    "│                         the creator's initials, and a short `-` delimited description, e.g.\n",
    "│                         `1.0-jqp-initial-data-exploration`.\n",
    "│\n",
    "├── pyproject.toml     <- Project configuration file with package metadata for \n",
    "│                         banknote_auth and configuration for tools like black\n",
    "│\n",
    "├── references         <- Data dictionaries, manuals, and all other explanatory materials.\n",
    "│\n",
    "├── reports            <- Generated analysis as HTML, PDF, LaTeX, etc.\n",
    "│   └── figures        <- Generated graphics and figures to be used in reporting\n",
    "│\n",
    "├── requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.\n",
    "│                         generated with `pip freeze > requirements.txt`\n",
    "│\n",
    "├── setup.cfg          <- Configuration file for flake8\n",
    "│\n",
    "└── banknote_auth   <- Source code for use in this project.\n",
    "    │\n",
    "    ├── __init__.py             <- Makes banknote_auth a Python module\n",
    "    │\n",
    "    ├── config.py               <- Store useful variables and configuration\n",
    "    │\n",
    "    ├── dataset.py              <- Scripts to download or generate data\n",
    "    │\n",
    "    ├── features.py             <- Code to create features for modeling\n",
    "    │\n",
    "    ├── modeling                \n",
    "    │   ├── __init__.py \n",
    "    │   ├── predict.py          <- Code to run model inference with trained models          \n",
    "    │   └── train.py            <- Code to train models\n",
    "    │\n",
    "    └── plots.py                <- Code to create visualizations\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec9013d-7590-4270-8d44-2dbbe6907456",
   "metadata": {},
   "source": [
    "## 4. Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134bb3ee-ffaf-4b6d-8544-69f3db49d61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "# Read the .txt file\n",
    "data = pd.read_csv(\"/Users/peter/banknote-authentication-ml/data/raw/data_banknote_authentication.txt\", header=None)\n",
    "\n",
    "# Add column names\n",
    "data.columns = [\"variance\", \"skewness\", \"curtosis\", \"entropy\", \"class\"]\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9eb8f1-77ea-444a-b2c2-9cdcaf6ad17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of the data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8864708-b6de-43c4-ae9d-9b5b92204c39",
   "metadata": {},
   "source": [
    "Showing the duplicated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8e97ce-9724-4996-98eb-45632f64e03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of duplicated rows\n",
    "num_duplicates = data.duplicated().sum()\n",
    "print(f\"Number of duplicated rows: {num_duplicates}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e3a3af-cff8-42d8-8b08-7b8d9b09f73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Duplicated values\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "print(f\"Shape after dropping duplicates: {data.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0260d2bd-699b-4716-b70f-4b274eeabe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns\n",
    "data = data.rename(columns={'variance':'Variance_Wavelet','skewness':'Skewness_Wavelet','curtosis':'Curtosis_Wavelet', \n",
    "                            'entropy':'Image_Entropy' ,'class':'Class'}, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe96e07e-96fe-420c-ae6d-07439f94d486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the cleaned DataFrame\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d33b8c0-3ea2-403f-8bd2-a87ed2c1b670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing value\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f282ccb5-4f25-4afb-b28f-a1596fe05b7f",
   "metadata": {},
   "source": [
    "## 5. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3aff9e-5c5b-4d0b-89bd-95f2dceb2696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the names of variable in the data \n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509747e8-7abe-4e0f-b3b1-8a3c91d57607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check the names of data type and non-null values \n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2f9612-97fd-4646-aa65-ae105e4d715e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the descriptive satistics of the data.\n",
    "# The summary of each numerical attribute.\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8990dd3-f547-4884-80ae-f62e777c6784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Verification\n",
    "print(\"=\"*50)\n",
    "print(\"Class Verification\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total samples: {len(data)}\")\n",
    "print(f\"Number of classes: {data['Class'].nunique()}\")\n",
    "print(\"\\nClass labels:\", data['Class'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e189711-d709-426c-bd0e-41fea0212b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Distribution - Numerical\n",
    "class_dist = data['Class'].value_counts().reset_index()\n",
    "class_dist.columns = ['Class', 'Count']\n",
    "class_dist['Percentage'] = (class_dist['Count'] / len(data)) * 100\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Class Distribution\")\n",
    "print(\"=\"*50)\n",
    "print(class_dist.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc50db8d-9c5b-4877-8242-1c9450bc4eed",
   "metadata": {},
   "source": [
    "##### Both the classes have nearly equal count, hence the dataset has good balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319fdc52-fb0e-4417-b416-2530a7fa839e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Distribution - Visual\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.countplot(x='Class', data=data, palette='viridis')\n",
    "plt.title('Class Count')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pie(class_dist['Count'], \n",
    "        labels=['Genuine (0)', 'Forged (1)'],\n",
    "        autopct='%1.1f%%',\n",
    "        colors=['#4CAF50', '#F44336'],\n",
    "        startangle=90)\n",
    "plt.title('Class Proportion')\n",
    "plt.tight_layout()\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e1474d-da16-4b50-8553-f8934a509f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance Check: To check if the dataset is balance or imbalance\n",
    "imbalance_ratio = class_dist['Count'].max() / class_dist['Count'].min()\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Balance Check\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Imbalance ratio: {imbalance_ratio:.2f}:1\")\n",
    "print(\"Interpretation:\")\n",
    "print(\"- Ratio close to 1:1 indicates balanced data\")\n",
    "print(f\"- Your data is {'balanced' if imbalance_ratio < 1.5 else 'moderately imbalanced'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7c12c8-f95d-4c51-ac4d-ee2b59464f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot the histogram to show a label that has class (0 = genuine, 1 = forged)\n",
    "plt.figure(figsize=(12, 8))\n",
    "features = data.columns[:-1]  # Exclude 'Class' column\n",
    "\n",
    "for i, label in enumerate(features):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    \n",
    "    # Plot histograms with KDE\n",
    "    sns.histplot(data=data[data[\"Class\"]==1], x=label, color=\"blue\", \n",
    "                 label=\"Forged\", kde=True, stat=\"density\", alpha=0.5)\n",
    "    sns.histplot(data=data[data[\"Class\"]==0], x=label, color=\"red\", \n",
    "                 label=\"Genuine\", kde=True, stat=\"density\", alpha=0.5)\n",
    "    \n",
    "    plt.title(f\"{label} Distribution\", fontweight='bold')\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.xlabel(\"\")\n",
    "    plt.legend()\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4c3c76-38f8-4f30-bf98-420fb074f1e1",
   "metadata": {},
   "source": [
    "### Key Findings by Feature\n",
    "1. Variance\n",
    "\n",
    "Clear Separation:\n",
    "\n",
    "* Genuine notes cluster around higher values (2-6)\n",
    "\n",
    "* Forged notes dominate lower ranges (-7 to 2)\n",
    "\n",
    "* Implication: Most discriminative feature for classification\n",
    "\n",
    "2. Skewness\n",
    "\n",
    "Bimodal Distribution:\n",
    "\n",
    "* Genuine: Peaks at ~8 (right-skewed) and ~-4 (left-skewed)\n",
    "\n",
    "* Forged: Concentrated near 0 with long tails\n",
    "\n",
    "Insight: Genuine notes show asymmetric printing patterns\n",
    "\n",
    "3. Curtosis\n",
    "\n",
    "Opposite Trends:\n",
    "\n",
    "* Genuine: Negative values (peaked distributions)\n",
    "\n",
    "* Forged: Positive values (flatter distributions)\n",
    "\n",
    "Significance: Measures sharpness differences in texture\n",
    "\n",
    "4. Entropy\n",
    "\n",
    "Overlap Area:\n",
    "\n",
    "* Both classes span -8 to 2 range\n",
    "\n",
    "* Genuine notes show tighter clustering\n",
    "\n",
    "Caution: Least discriminative single feature\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95396991-1dea-45fe-a9e5-0ffb820f2a90",
   "metadata": {},
   "source": [
    "#### Pairplots to visualize feature relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbb9270-348b-4cb8-88e0-5aa91b5bf5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pairplots to visualize feature relationships\n",
    "\n",
    "## Let's plot pairwise plot\n",
    "sns.pairplot(data, hue=\"Class\");\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b025e08-3c9b-474e-8b93-a6de1b61fc1f",
   "metadata": {},
   "source": [
    "sns.pairplot(df, hue = \"Class\") generates a pair plot of the variables in the DataFrame data, where data points are colored based on the categories in the \"Class\" variable. \n",
    "This can be helpful for visualizing relationships between variables and identifying patterns or clusters within the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df8b339-4fda-47d0-813d-fd6e3661e6c7",
   "metadata": {},
   "source": [
    "### Using Interquantilke Range (IQR) to Detect and Remove Outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298a970d-855f-4f44-8df5-c9a911cbee57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a function to detect outliers using IQR\n",
    "def detect_outliers_iqr(series):\n",
    "    Q1 = series.quantile(0.25)\n",
    "    Q3 = series.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return (series < lower_bound) | (series > upper_bound)\n",
    "\n",
    "# Apply the function to each numerical column in the DataFrame\n",
    "outliers_iqr = data.select_dtypes(include=['number']).apply(detect_outliers_iqr)\n",
    "\n",
    "# Summarize the results\n",
    "print(\"Outliers detected using IQR:\")\n",
    "\n",
    "print(outliers_iqr.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d835ebab-6fef-475b-80a4-ef154408c1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate outliers using IQR method 2\n",
    "for feature in ['Variance_Wavelet', 'Skewness_Wavelet', 'Curtosis_Wavelet', 'Image_Entropy']:\n",
    "    q1 = data[feature].quantile(0.25)\n",
    "    q3 = data[feature].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    \n",
    "    lower = q1 - 1.5*iqr\n",
    "    upper = q3 + 1.5*iqr\n",
    "    \n",
    "    outliers = data[(data[feature] < lower) | (data[feature] > upper)]\n",
    "    print(f\"\\n{feature}: {len(outliers)} outliers\")\n",
    "    print(outliers['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168232e6-78d6-46c6-b6c6-cf6562903bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let visualize it using Boxplot\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Identify outliers in all features\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=data.melt(id_vars='Class'), \n",
    "            x='variable', y='value', hue='Class',\n",
    "            palette={0: 'green', 1: 'red'})\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('All Features Comparison', fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad805da-5463-4dd7-9172-acbae3216c59",
   "metadata": {},
   "source": [
    "### Remove Outliers Using IQR Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809aead4-e691-4e14-984d-c4a96204a83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define original size\n",
    "original_size = len(data)\n",
    "\n",
    "# Define features to apply IQR to\n",
    "features = data.select_dtypes(include='number').columns  # or manually specify list\n",
    "\n",
    "# Function to remove outliers using IQR\n",
    "def remove_outliers_iqr(data, feature_columns, factor=1.0):\n",
    "    data_clean = data.copy()\n",
    "    for col in feature_columns:\n",
    "        Q1 = data_clean[col].quantile(0.25)\n",
    "        Q3 = data_clean[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - factor * IQR\n",
    "        upper_bound = Q3 + factor * IQR\n",
    "        data_clean = data_clean[(data_clean[col] >= lower_bound) & (data_clean[col] <= upper_bound)]\n",
    "    return data_clean\n",
    "\n",
    "# Apply function\n",
    "data_no_outliers = remove_outliers_iqr(data, features, factor=1.0)\n",
    "\n",
    "# Report results\n",
    "print(f\"Removed {original_size - len(data_no_outliers)} outliers ({(original_size - len(data_no_outliers))/original_size:.1%})\")\n",
    "print(f\"New dataset size: {len(data_no_outliers)} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f793ea7a-b6e1-4a2f-8d09-510ad4ffa5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual Verification (Before & After)\n",
    "# Set style\n",
    "sns.set(style=\"whitegrid\")\n",
    "features = ['Variance_Wavelet', 'Skewness_Wavelet', 'Curtosis_Wavelet', 'Image_Entropy']\n",
    "\n",
    "# Plot boxplots side by side\n",
    "fig, axes = plt.subplots(nrows=4, ncols=2, figsize=(12, 16))\n",
    "fig.suptitle('Boxplots Before and After Outlier Removal', fontsize=16)\n",
    "\n",
    "for i, col in enumerate(features):\n",
    "    sns.boxplot(data=data, x=col, ax=axes[i, 0], color='skyblue')\n",
    "    axes[i, 0].set_title(f\"{col} (Before)\")\n",
    "    \n",
    "    sns.boxplot(data=data_no_outliers, x=col, ax=axes[i, 1], color='lightgreen')\n",
    "    axes[i, 1].set_title(f\"{col} (After)\")\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.97])\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc95aa97-f2bb-42c4-aee8-f1f8002c60e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are still an outlier\n",
    "\n",
    "# Define a function to detect outliers using IQR\n",
    "def detect_outliers_iqr(series):\n",
    "    Q1 = series.quantile(0.25)\n",
    "    Q3 = series.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return (series < lower_bound) | (series > upper_bound)\n",
    "\n",
    "# Apply the function to each numerical column in the DataFrame\n",
    "outliers_iqr = data_no_outliers.select_dtypes(include=['number']).apply(detect_outliers_iqr)\n",
    "\n",
    "# Summarize the results\n",
    "print(\"Outliers detected using IQR:\")\n",
    "\n",
    "print(outliers_iqr.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6640d8-d8a0-4656-bf5d-278e446ac9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the original shape $ shape after removing an outliers\n",
    "print(f\"Original shape: {data.shape}\")\n",
    "print(f\"Data shape after removed outliers: {data_no_outliers.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a4540b-ef69-44e5-9581-8b214ce1e6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming my data_no_outliers\n",
    "data_cleaned = data_no_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d493e7-f9bb-4395-bf1e-d663be91024a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21940688-4ed6-4a29-afcb-21fc4e452e40",
   "metadata": {},
   "source": [
    "### Save the cleaned data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a64e58-6b8c-44f2-a978-9576b221661b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Ensure the processed data directory exists\n",
    "os.makedirs(\"data/processed\", exist_ok=True)\n",
    "\n",
    "# Save cleaned data to the correct path\n",
    "data_cleaned.to_csv(\"data/processed/data_cleaned.csv\", index=False, sep='\\t')\n",
    "\n",
    "print(\"data_cleaned.csv saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8856bf-2ea0-42a7-9f3d-e32f38587f63",
   "metadata": {},
   "source": [
    "### Use this data_cleaned.csv output for data/processed/data_cleaned.csv on cookiecutter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7c4dc6-04ee-47da-b9e2-54a18ba24483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this data_cleaned.csv output for data/processed/data_cleaned.csv on cookiecutter\n",
    "\n",
    "#import pandas as pd\n",
    "#import sys\n",
    "\n",
    "# Load the cleaned data\n",
    "#df = pd.read_csv(\"data/processed/data_cleaned.csv\")\n",
    "\n",
    "# Print as CSV to output (without the index)\n",
    "#df.to_csv(sys.stdout, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4969ee1c-0d92-4179-abde-55e9eeacf8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the CSV file exists and print its size\n",
    "csv_path = \"data/data_cleaned.csv\"\n",
    "print(\"CSV exists:\", os.path.exists(csv_path))\n",
    "print(\"CSV size:\", os.path.getsize(csv_path) if os.path.exists(csv_path) else \"File not found\")\n",
    "# Display the shape of the data\n",
    "print(\"Data shape:\", data_cleaned.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7d6aff-dcd6-41f2-83d1-2c66095f88ff",
   "metadata": {},
   "source": [
    "### Correlation Analysis - HeatMap\n",
    "\n",
    "* Correlaton Analysis they should not be no perfect multicollnearity (if there is drop one independent variable)\n",
    "* Light Green - Strong negative correlation\n",
    "* Dark Green - Strong positive correlation\n",
    "* -1 mean strong negative correlation\n",
    "* +1 means strong positive correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604413e8-6c41-4870-880a-d32e5c7198be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure only numeric columns are used for correlation\n",
    "numeric_data = data_cleaned.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = numeric_data.corr()\n",
    "\n",
    "# Plot the heatmap\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"Greens\")\n",
    "plt.title(\"Correlation Heatmap of Banknote Authentication\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49f8c6c-44dd-4dd8-8bb2-32591d033c8c",
   "metadata": {},
   "source": [
    "#### Observations from the Correlation Analysis above\n",
    "\n",
    "Variance_Wavelet = -0.74\n",
    "\n",
    "* Strong negative correlation with Class\n",
    "\n",
    "* As variance increases, the probability that a note is forged (Class=1) decreases\n",
    "\n",
    "* So higher variance is more likely associated with authentic notes\n",
    "\n",
    "Skewness_Wavelet = -0.43\n",
    "\n",
    "* Moderate negative correlation\n",
    "\n",
    "* Higher skewness also tends to be associated with authentic banknotes\n",
    "\n",
    "Curtosis_Wavelet = -0.04\n",
    "\n",
    "* Very weak negative correlation\n",
    "\n",
    "* This feature is not very informative on its own\n",
    "\n",
    "Image_Entropy = 0.01\n",
    "\n",
    "* Almost no correlation with the target\n",
    "\n",
    "* Might not help much in linear models, but could still help in tree-based models that capture interactions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d7e22c-ffba-422e-a22d-0ec40062880a",
   "metadata": {},
   "source": [
    "#### Check multicollinearity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7faf627-1c84-4c7a-98b2-8351b0879dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check multicollinearity using\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Calculate VIF\n",
    "from statsmodels.tools.tools import add_constant\n",
    "X = add_constant(numeric_data.drop(columns='Class'))\n",
    "pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'VIF': [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdfc17b-b9c9-4fcc-b943-30ae454e6ca7",
   "metadata": {},
   "source": [
    "#### Findings\n",
    "\n",
    "VIF < 5 is generally acceptable.\n",
    "\n",
    "VIF > 10 indicates serious multicollinearity (none of the features are there).\n",
    "\n",
    "Even though Skewness_Wavelet and Image_Entropy are moderately correlated (-0.65), their VIFs are still in a safe range."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85043bd-9b25-4b83-88a4-e243deaea7bf",
   "metadata": {},
   "source": [
    "#### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7902413-e0ba-4440-96f5-cdb4d7d6db44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix with the Class\n",
    "corr_matrix = data_cleaned.corr()\n",
    "corr_matrix[\"Class\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4d1806-a661-4ae7-bdd5-4238d6536915",
   "metadata": {},
   "source": [
    "### 5.1 EDA Summary\n",
    "\n",
    "* The dataset is very clean and has no null values present.\n",
    "\n",
    "* There is no multicolliniraty on the data_cleaned\n",
    "\n",
    "* Class variable is fairly balanced, 55% zero to 45% one\n",
    "\n",
    "* Correlations: Correlation between features is weak at best\n",
    "\n",
    "* From features Variance_Wavelet, Skewness_Wavelet, Curtosis_Wavelet and Image_Entropy are reasonabily fairly correlated with the target variable at --0.74, -0.43, -0.04, 0.01 correlation coefficient respectively.\n",
    "\n",
    "* Curtosis_Wavelet & Image_Entropy has less correlation with Class.\n",
    "\n",
    "* Before removing outliers, Curtosis_Wavelet & Image_Entropy has 59 & 32 outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c57884d-8d55-4d92-823b-1915b21d528d",
   "metadata": {},
   "source": [
    "## 6. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b73868-b7c6-4854-af28-b51c725183ca",
   "metadata": {},
   "source": [
    "### 6.1 Define Dependent and Independent Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2c7bf7-c96a-40e1-bfa3-694d75a3ebf4",
   "metadata": {},
   "source": [
    "### 6.2 Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e992663f-a1cf-4934-b122-11314d6e604d",
   "metadata": {},
   "source": [
    "### 6.3 Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b98bf41-9e5b-43ad-8c37-b6b9bbbb1eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Split first (on the raw features)\n",
    "# Features and target (workaround)\n",
    "X = data_cleaned.iloc[:, :-1]\n",
    "y = data_cleaned.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dca5f9-7b85-4a69-8146-c386bc362446",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Step 2: Scale only on training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Check the size of the training and testing sets\n",
    "print(\"X_train size:\", X_train.shape)\n",
    "print(\"X_test size:\", X_test.shape)\n",
    "print(\"y_train size:\", len(y_train))\n",
    "print(\"y_test size:\", len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f655ec-7adb-4044-9b5e-86ed418ff32e",
   "metadata": {},
   "source": [
    "## 7. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db08f738-93ff-4a23-80e6-13be83b7a2cc",
   "metadata": {},
   "source": [
    "### 7.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f6e370-96f6-4606-8bbc-15d7cbd70ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = LogisticRegression()\n",
    "log_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae54d1e2-c641-43ad-b757-b72da3da58f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Prediction on test_scaled\n",
    "log_y_pred = log_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3257dde5-e9fc-4e6d-b73f-14cefb96444d",
   "metadata": {},
   "source": [
    "#### Log Reg Hyperparameter Tuning with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e1219c-0f67-4fc3-a4cc-76594f36ac51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base model\n",
    "log_model = LogisticRegression(solver='liblinear')  # 'liblinear' works well for small datasets and supports l1/l2 penalty\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': np.logspace(-3, 3, 7),  # Regularization strength: 0.001 to 1000\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=log_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1',            # You can also use 'accuracy', 'roc_auc', etc.\n",
    "    cv=5,                    # 5-fold cross-validation\n",
    "    verbose=1,\n",
    "    n_jobs=-1                # Use all CPU cores\n",
    ")\n",
    "\n",
    "# Fit to training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best hyperparameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "log_accuracy = accuracy_score(y_test, log_y_pred)\n",
    "log_conf_matrix = confusion_matrix(y_test, log_y_pred)\n",
    "log_report = classification_report(y_test, log_y_pred)\n",
    " \n",
    "# Output results, classification reports, and plot confusion matrix\n",
    "print(\"\\n=== Log Results ===\")\n",
    "print(f\"Accuracy: {log_accuracy:.2f}\")\n",
    "#print(\"Log Classification Report:\\n\", log_report)\n",
    "print(\"Classification Report on Test Set:\")\n",
    "print(classification_report(y_test, log_y_pred))\n",
    "\n",
    "# Plot confusion matrix\n",
    "# Plot confusion matrix without grid lines\n",
    "fig, ax = plt.subplots()\n",
    "disp = ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test,\n",
    "    log_y_pred,\n",
    "    cmap='Blues',\n",
    "    ax=ax\n",
    ")\n",
    "disp.im_.colorbar.remove()  # Optional: remove color bar if you want an even cleaner look\n",
    "ax.grid(False)              # Turn off grid\n",
    "plt.title(\"Confusion Matrix - Log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaaba25-300f-43d2-ac24-2d63006a3afe",
   "metadata": {},
   "source": [
    "#### Checking Logistic Regression Scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c21394d-aa32-4db6-8368-55494f1ef44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model first\n",
    "log_model = LogisticRegression(solver='liblinear')  # or any other solver\n",
    "log_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = log_model.predict(X_train)\n",
    "y_test_pred = log_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "log_scores = {\n",
    "    \"log_train\": {\n",
    "        \"accuracy\": accuracy_score(y_train, y_train_pred),\n",
    "        \"recall\": recall_score(y_train, y_train_pred),\n",
    "        \"precision\": precision_score(y_train, y_train_pred),\n",
    "        \"f1-score\": f1_score(y_train, y_train_pred)\n",
    "    },\n",
    "    \"log_test\": {\n",
    "        \"accuracy\": accuracy_score(y_test, y_test_pred),\n",
    "        \"recall\": recall_score(y_test, y_test_pred),\n",
    "        \"precision\": precision_score(y_test, y_test_pred),\n",
    "        \"f1-score\": f1_score(y_test, y_test_pred)\n",
    "    }\n",
    "}\n",
    "\n",
    "D_log_scores = pd.DataFrame(log_scores)\n",
    "D_log_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4face05c-2428-41c0-9140-1a301baf9bc1",
   "metadata": {},
   "source": [
    "* Findings\n",
    "\n",
    "Accuracy and F1-score drop slightly on the test set — but not significantly.\n",
    "\n",
    "Recall remains perfect (1.0) on both sets — the model is catching all positives in both train and test.\n",
    "\n",
    "Precision is slightly lower on test data, but still very high.\n",
    "\n",
    "* Conclusion\n",
    "\n",
    "This model is:\n",
    "\n",
    "Not overfitting: Small performance drop from train to test is normal.\n",
    "\n",
    "Not underfitting: Very high scores on both train and test.\n",
    "\n",
    "Generalizing well: Differences are within a healthy range.\n",
    "\n",
    "* Overall: This is a good fit.\n",
    "\n",
    "The model performs consistently and robustly on both training and test data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc39dea7-742d-47fb-b1ef-c15f6615bfff",
   "metadata": {},
   "source": [
    "#### Evaluating ROC Curves and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e64e95c-34a4-4842-8685-794067120758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities for the positive class\n",
    "y_proba = log_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Compute ROC curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f\"Logistic Regression (AUC = {roc_auc:.2f})\", color='navy')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')  # Diagonal line\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve - Logistic Regression\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b158b77-c7f0-49cc-b73e-910c6e09cef3",
   "metadata": {},
   "source": [
    "Findings:\n",
    "\n",
    "AUC (Area Under Curve) summarizes the model’s ability to distinguish between classes.\n",
    "\n",
    "AUC close to 1.0 → excellent classifier.\n",
    "\n",
    "AUC around 0.5 → random guess."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86060ef3-15ac-4516-a432-7c8196c2bab8",
   "metadata": {},
   "source": [
    "### 7.2 K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132d590f-98a7-4e33-96b6-48cd6aec6d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors= 5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "knn_y_pred = knn_model.predict(X_test)\n",
    "knn_y_pred_proba = knn_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d355fa96-cb24-4d67-bb2d-949e0b1972af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking KNN Accuracy score, Classification Report & Confusion Matrix before Tune\n",
    "knn_accuracy = accuracy_score(y_test, knn_y_pred)\n",
    "knn_conf_matrix = confusion_matrix(y_test, knn_y_pred)\n",
    "knn_report = classification_report(y_test, knn_y_pred)\n",
    " \n",
    "# Output results, classification reports, and plot confusion matrix\n",
    "print(\"\\n=== KNN Results ===\")\n",
    "print(f\"Accuracy: {knn_accuracy:.2f}\")\n",
    "#print(\"Log Classification Report:\\n\", log_report)\n",
    "print(\"Classification Report on Test Set:\")\n",
    "print(classification_report(y_test, knn_y_pred))\n",
    "\n",
    "# Plot confusion matrix\n",
    "fig, ax = plt.subplots()\n",
    "disp = ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test,\n",
    "    knn_y_pred,\n",
    "    cmap='Blues',\n",
    "    ax=ax\n",
    ")\n",
    "disp.im_.colorbar.remove()  # Optional: remove color bar if you want an even cleaner look\n",
    "ax.grid(False)              # Turn off grid\n",
    "plt.title(\"Confusion Matrix - KNN\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b75716f-c689-4cd8-8a46-733d406c8b1a",
   "metadata": {},
   "source": [
    "#### GridSearch with KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7f4a54-9d48-47ac-8f5e-19fa917f53e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_grid = KNeighborsClassifier()\n",
    "k_values = range(1, 30)\n",
    "param_grid = {\"n_neighbors\":k_values, \"p\": [1,2], \"weights\": ['uniform',\"distance\"]}\n",
    "knn_grid = GridSearchCV(knn_grid, param_grid, cv = 10, scoring= \"accuracy\")\n",
    "knn_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f50eb9-6191-4c98-af24-c6176e63469e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(knn_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab42af98-ffe7-466c-85a8-44526ce14caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(knn_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3e1258-329d-4524-a79e-d6742b0f71d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors= 2, p = 1)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2048c7-f90e-4af5-b4ca-76bfa2a2a772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Decision Tree Accuracy score, Classification Report & Confusion Matrix after Tuning\n",
    "best_knn = grid_search.best_estimator_  # or the tuned KNN model\n",
    "\n",
    "# Predict on test data\n",
    "knn_y_pred = best_knn.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, knn_y_pred)\n",
    "print(f\"Accuracy on Test Set: {accuracy:.4f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report on Test Set:\")\n",
    "print(classification_report(y_test, knn_y_pred))\n",
    "\n",
    "# Plot confusion matrix\n",
    "fig, ax = plt.subplots()\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test,\n",
    "    knn_y_pred,\n",
    "    cmap='Blues',\n",
    "    ax=ax\n",
    ")\n",
    "plt.title(\"Confusion Matrix - Tuned KNN\")\n",
    "plt.grid(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410af0a5-8e0a-428d-93f9-dce7b0a83a46",
   "metadata": {},
   "source": [
    "#### Checking KNN Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f7b667-131e-4c0e-b4a5-33cae6a1eb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = knn_model.predict(X_train)\n",
    "y_pred = knn_model.predict(X_test)\n",
    "knn_scores = {\"knn_train\": {\"accuracy\" : accuracy_score(y_train, y_train_pred),\n",
    "                          \"recall\"   : recall_score(y_train, y_train_pred),\n",
    "                          \"precision\": precision_score(y_train, y_train_pred),\n",
    "                          \"f1-score\" : f1_score(y_train, y_train_pred)} ,\n",
    "             \"knn_test\": {\"accuracy\" : accuracy_score(y_test, y_pred),\n",
    "                         \"recall\" : recall_score(y_test, y_pred),\n",
    "                         \"precision\" : precision_score(y_test, y_pred),\n",
    "                         \"f1-score\" : f1_score(y_test, y_pred)}}\n",
    "D_knn =pd.DataFrame(knn_scores)\n",
    "D_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224e4761-5977-40e3-a749-1cfd8852d60a",
   "metadata": {},
   "source": [
    " Findings:\n",
    "\n",
    "Train and test scores are nearly identical — suggesting excellent generalization.\n",
    "\n",
    "Perfect recall on both sets means no false negatives (i.e. no missed positive cases).\n",
    "\n",
    "High precision on both sets indicates very few false positives.\n",
    "\n",
    "Tiny performance gap between training and testing → not overfitting.\n",
    "\n",
    "Very high scores overall → not underfitting.\n",
    "\n",
    "Conclusion\n",
    "    \n",
    "Your KNN model is a good fit.\n",
    "    \n",
    "It generalizes well and achieves excellent performance on both training and testing data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f998542e-1f96-4c04-af2e-4203824f8c96",
   "metadata": {},
   "source": [
    "#### Evaluating ROC Curves and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a42a0c-2210-4686-9ff3-779090f9fd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities for the positive class\n",
    "y_proba = knn_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Calculate FPR, TPR and AUC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC Curve & AUC\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f\"KNN (AUC = {roc_auc:.2f})\", color=\"darkgreen\")\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve - KNN\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe76a95d-70ad-4d5f-a699-674070b79679",
   "metadata": {},
   "source": [
    "Observation:\n",
    "\n",
    "AUC closer to 1.0 = better classification performance.\n",
    "\n",
    "KNN can perform well with a good choice of n_neighbors and scaled data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a4e941-a2c9-4064-b543-17fc95a664d0",
   "metadata": {},
   "source": [
    "### 7.3 Support Vector Machine (SVM) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47e930c-6a9b-4628-aaf8-feba3c125565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "svc_model = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "svc_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68513f7a-75d4-49e6-a61a-f2768644e4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "svc_y_pred = svc_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8644602-b404-4842-a29d-f32002ec694b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking KNN Accuracy score, Classification Report & Confusion Matrix before Tuning\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "svc_accuracy = accuracy_score(y_test, svc_y_pred)\n",
    "svc_conf_matrix = confusion_matrix(y_test, svc_y_pred)\n",
    "svc_report = classification_report(y_test, svc_y_pred)\n",
    " \n",
    "# Output results, classification reports, and plot confusion matrix\n",
    "print(\"\\n=== SVM Results ===\")\n",
    "print(f\"Accuracy: {svc_accuracy:.2f}\")\n",
    "print(\"Classification Report on Test Set:\")\n",
    "print(classification_report(y_test, svc_y_pred))\n",
    "\n",
    "# Plot confusion matrix without grid lines\n",
    "fig, ax = plt.subplots()\n",
    "disp = ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test,\n",
    "    svc_y_pred,\n",
    "    cmap='Blues',\n",
    "    ax=ax\n",
    ")\n",
    "disp.im_.colorbar.remove()  # Optional: remove color bar if you want an even cleaner look\n",
    "ax.grid(False)              # Turn off grid\n",
    "plt.title(\"Confusion Matrix - SVM\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd374674-9bda-443d-9273-981b5c60b0cf",
   "metadata": {},
   "source": [
    "#### Checking SVM Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58f1fc2-1771-4d28-97b8-a267f416277b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = svc_model.predict(X_train)\n",
    "svc_y_pred = svc_model.predict(X_test)\n",
    "\n",
    "svm_scores = {\"svm_train\": {\"accuracy\" : accuracy_score(y_train, y_train_pred),\n",
    "                          \"recall\"   : recall_score(y_train, y_train_pred),\n",
    "                          \"precision\": precision_score(y_train, y_train_pred),\n",
    "                          \"f1-score\" : f1_score(y_train, y_train_pred)} ,\n",
    "             \"svm_test\": {\"accuracy\" : accuracy_score(y_test, y_pred),\n",
    "                         \"recall\" : recall_score(y_test, y_pred),\n",
    "                         \"precision\" : precision_score(y_test, y_pred),\n",
    "                         \"f1-score\" : f1_score(y_test, y_pred)}}\n",
    "D_svm =pd.DataFrame(svm_scores)\n",
    "D_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22951a3c-3193-42a6-9917-1d9a1adf1d87",
   "metadata": {},
   "source": [
    " Observations:\n",
    "\n",
    "* Extremely high scores across both train and test sets.\n",
    "\n",
    "* Perfect recall → model is catching all true positives.\n",
    "\n",
    "* Precision and F1-score are very close between train and test sets.\n",
    "\n",
    "* The small drop in performance is expected and acceptable.\n",
    "\n",
    "Conclusion:\n",
    "\n",
    "This SVM model is a good fit.\n",
    "\n",
    "It generalizes very well, shows no overfitting, and maintains high precision and recall — making it a reliable classifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15d5538-b4a2-48f8-92f9-9b783e4b61be",
   "metadata": {},
   "source": [
    "#### GridSearch with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac65b12-3072-4878-af71-ca4b84267271",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "svc_model = SVC(random_state=42)\n",
    "svc = SVC()\n",
    "param_grid = {'C':[1,10,100],\n",
    "              'kernel':['linear','rbf','sigmoid','poly'],\n",
    "              'gamma':[\"scale\", \"auto\"],\n",
    "              'degree':[1,2]}\n",
    "grid = GridSearchCV(svc_model,param_grid)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d438ca2b-6710-4588-94b2-a8a5b6426722",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a3be35-92de-4d9a-9e39-d0cef6a6e7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b25b594-14ae-45df-b4c4-961d35ac589e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking SVM Accuracy score, Classification Report & Confusion Matrix after Tuning\n",
    "best_svc = grid_search.best_estimator_\n",
    "\n",
    "# Predict on test data\n",
    "svc_y_pred = best_svc.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, svc_y_pred)\n",
    "print(f\"Accuracy on Test Set: {accuracy:.4f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report on Test Set:\")\n",
    "print(classification_report(y_test, svc_y_pred))\n",
    "\n",
    "# Plot confusion matrix\n",
    "fig, ax = plt.subplots()\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test,\n",
    "    svc_y_pred,\n",
    "    cmap='Blues',\n",
    "    ax=ax\n",
    ")\n",
    "plt.title(\"Confusion Matrix - Tuned SVM\")\n",
    "plt.grid(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9943d94-5446-48bc-ad9f-d068c67a544e",
   "metadata": {},
   "source": [
    "#### Evaluating ROC Curves and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61796b89-7df3-4ab3-bfa7-c52412feced5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVMs don’t output probabilities by default,\n",
    "# so you must set probability=True when initializing the model.\n",
    "\n",
    "# Initialize SVM with probability output\n",
    "svc_model = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities for the positive class\n",
    "y_proba = svc_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Compute ROC curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC Curve & AUC\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f\"SVM (AUC = {roc_auc:.2f})\", color=\"purple\")\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve - SVM\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2640f45-d635-4eeb-a6d8-aff2126afe56",
   "metadata": {},
   "source": [
    "Interpretation:\n",
    "\n",
    "AUC close to 1.0 → excellent classification\n",
    "\n",
    "AUC around 0.5 → model is no better than random guessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60a0458-0cb1-4711-8114-75decaacc781",
   "metadata": {},
   "source": [
    "### 7.4 Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd85c4e-7f91-4c23-912b-571f38cf382b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeClassifier(criterion= \"gini\", min_samples_split= 2)\n",
    "dt_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64635cb-bae3-4eb6-ae20-3a99598ab140",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_y_pred = dt_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7530478-cab7-4813-8b32-f1b674e1cad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Decision Tree Accuracy score, Classification Report & Confusion Matrix before Tuning\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "dt_accuracy = accuracy_score(y_test, dt_y_pred)\n",
    "dt_conf_matrix = confusion_matrix(y_test, dt_y_pred)\n",
    "dt_report = classification_report(y_test, dt_y_pred)\n",
    " \n",
    "# Output results, classification reports, and plot confusion matrix\n",
    "print(\"\\n=== Decision Tree Results ===\")\n",
    "print(f\"Accuracy: {dt_accuracy:.2f}\")\n",
    "print(\"Classification Report on Test Set:\")\n",
    "print(classification_report(y_test, dt_y_pred))\n",
    "\n",
    "# Plot confusion matrix\n",
    "fig, ax = plt.subplots()\n",
    "disp = ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test,\n",
    "    dt_y_pred,\n",
    "    cmap='Blues',\n",
    "    ax=ax\n",
    ")\n",
    "disp.im_.colorbar.remove()  # Optional: remove color bar if you want an even cleaner look\n",
    "ax.grid(False)              # Turn off grid\n",
    "plt.title(\"Confusion Matrix - Decision Tree\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e44e72f-674e-4c1d-bd9d-078e17033138",
   "metadata": {},
   "source": [
    "#### GridSearch with Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d906ed99-fea9-4ec6-a063-cc6c45c45483",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "param_grid = {\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [6,7,8],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "dt_grid = GridSearchCV(estimator=dt, param_grid=param_grid, cv= 5)\n",
    "dt_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c07a36-f517-4574-89c9-c3469292aaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dt_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a1574d-d115-4af0-bf84-365c5fc7c725",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dt_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d649d177-3e75-4e2b-92ed-e5a8eae70f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Decision Tree Accuracy score, Classification Report & Confusion Matrix after Tuning\n",
    "best_dt = grid_search.best_estimator_\n",
    "\n",
    "# Predict on test data\n",
    "dt_y_pred = best_dt.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, dt_y_pred)\n",
    "print(f\"Accuracy on Test Set: {accuracy:.4f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report on Test Set:\")\n",
    "print(classification_report(y_test, dt_y_pred))\n",
    "\n",
    "# Plot confusion matrix\n",
    "fig, ax = plt.subplots()\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test,\n",
    "    dt_y_pred,\n",
    "    cmap='Blues',\n",
    "    ax=ax\n",
    ")\n",
    "plt.title(\"Confusion Matrix - Tuned Decision Tree\")\n",
    "plt.grid(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31218735-a170-4f73-a5b4-6c435f1846d2",
   "metadata": {},
   "source": [
    "#### Checking Decision Tree Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739d1a0d-16ee-40e1-8fd1-60b6c1ed84f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = dt_grid.predict(X_train)\n",
    "y_pred = dt_grid.predict(X_test)\n",
    "dt_scores = {\"dt_train\": {\"accuracy\" : accuracy_score(y_train, y_train_pred),\n",
    "                          \"recall\"   : recall_score(y_train, y_train_pred),\n",
    "                          \"precision\": precision_score(y_train, y_train_pred),\n",
    "                          \"f1-score\" : f1_score(y_train, y_train_pred)} ,\n",
    "             \"dt_test\": {\"accuracy\" : accuracy_score(y_test, y_pred),\n",
    "                         \"recall\" : recall_score(y_test, y_pred),\n",
    "                         \"precision\" : precision_score(y_test, y_pred),\n",
    "                         \"f1-score\" : f1_score(y_test, y_pred)}}\n",
    "D_dt_scores =pd.DataFrame(dt_scores)\n",
    "D_dt_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feed9dc2-2e25-4804-b6a2-15dabab69f6d",
   "metadata": {},
   "source": [
    "Interpretation:\n",
    "\n",
    "* High accuracy and high F1-score on both training and test sets.\n",
    "\n",
    "* Perfect recall on training vs. slightly lower on test → mild signs of overfitting.\n",
    "\n",
    "* Still, generalization is strong — the drop is small and within acceptable bounds.\n",
    "\n",
    "Conclusion:\n",
    "⚖️ Mild Overfitting, but overall still a very good fit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc714a2-a412-4bd9-9271-b168dbbc5a1c",
   "metadata": {},
   "source": [
    "#### Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a1c066-947d-4866-8fc6-cf5333d12871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example if you know your features\n",
    "feature_names = [\"Variance_Wavelet\", \"Skewness_Wavelet\", \"Curtosis_Wavelet\", \"Image_Entropy\"]  # Replace with the actual names\n",
    "feats = pd.DataFrame(index=feature_names, data=dt_model.feature_importances_, columns=[\"dt_importance\"])\n",
    "dt_imp_feats = feats.sort_values(\"dt_importance\", ascending=False)\n",
    "print(dt_imp_feats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8d2785-99bf-4a15-83c1-1ee9241103ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barplot for dt feature Imptance\n",
    "sns.barplot(data=dt_imp_feats, x=dt_imp_feats.index, y='dt_importance')\n",
    "\n",
    "# Rotate x-axis labels\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()  # optional, to avoid label cutoff\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffc9e7d-5542-4dd3-9afe-aaaee32b87f6",
   "metadata": {},
   "source": [
    "#### Evaluating ROC Curves and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ea6a93-acde-4c97-a900-7d5d11cffc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted probabilities for class 1\n",
    "y_proba = dt_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Compute FPR, TPR, and thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC Curve and AUC\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f\"Decision Tree (AUC = {roc_auc:.2f})\", color=\"darkorange\")\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")  # Random baseline\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve - Decision Tree\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bd2d5e-aa10-4f31-b5a0-f9488ccde5da",
   "metadata": {},
   "source": [
    "ROC curve shows the trade-off between sensitivity (TPR) and fallout (FPR).\n",
    "\n",
    "AUC score (0.0–1.0) summarizes performance:\n",
    "\n",
    "0.5 = random guess\n",
    "\n",
    "0.7–0.8 = acceptable\n",
    "\n",
    "0.8–0.9 = good\n",
    "\n",
    "0.9–1.0 = excellent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc6b0b3-d8eb-4dfa-b49c-b161026ebe44",
   "metadata": {},
   "source": [
    "### 7.5 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0400ad90-2926-4ccf-99f3-ab560c26bf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29c6cd0-7964-41ed-b594-607cc433a2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Prediction \n",
    "rt_y_pred = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480a2be9-8810-4bdf-a6db-e707ac347f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Randomforest Accuracy score, Classification Report & Confusion Matrix before Tuning\n",
    "rt_accuracy = accuracy_score(y_test, rt_y_pred)\n",
    "rt_conf_matrix = confusion_matrix(y_test, rt_y_pred)\n",
    "rt_report = classification_report(y_test, rt_y_pred)\n",
    " \n",
    "# Output results, classification reports, and plot confusion matrix\n",
    "print(\"\\n=== RandomForest Results ===\")\n",
    "print(f\"Accuracy: {rt_accuracy:.2f}\")\n",
    "print(\"Classification Report on Test Set:\")\n",
    "print(classification_report(y_test, rt_y_pred))\n",
    "\n",
    "# Plot confusion matrix\n",
    "fig, ax = plt.subplots()\n",
    "disp = ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test,\n",
    "    rt_y_pred,\n",
    "    cmap='Blues',\n",
    "    ax=ax\n",
    ")\n",
    "disp.im_.colorbar.remove()  # Optional: remove color bar if you want an even cleaner look\n",
    "ax.grid(False)              # Turn off grid\n",
    "plt.title(\"Confusion Matrix - RandomForest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901820b4-87bc-4956-8b18-29e766fa94e1",
   "metadata": {},
   "source": [
    "#### GridSearch with RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89489c2f-3d27-4932-ab15-d4ec1835e293",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier(random_state=42)\n",
    "param_grid = {\n",
    "    'n_estimators': [15,35,55],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [6,7,8],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "rf_grid = GridSearchCV(estimator=rf, param_grid=param_grid, cv= 5)\n",
    "rf_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72886b56-e6ba-4490-bdf0-fe4d237eb8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef99f92-4a7d-4c83-8322-0f2b735acb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a8c96c-2da7-4faf-bb5d-514ff5ec7ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking RandomForest Accuracy score, Classification Report & Confusion Matrix after Tuning\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Predict on test data\n",
    "rf_y_pred = best_rf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, rf_y_pred)\n",
    "print(f\"Accuracy on Test Set: {accuracy:.4f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report on Test Set:\")\n",
    "print(classification_report(y_test, rf_y_pred))\n",
    "\n",
    "# Plot confusion matrix\n",
    "fig, ax = plt.subplots()\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test,\n",
    "    rf_y_pred,\n",
    "    cmap='Blues',\n",
    "    ax=ax\n",
    ")\n",
    "plt.title(\"Confusion Matrix - Tuned Decision Tree\")\n",
    "plt.grid(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211b01b8-46eb-40e1-8683-3fdcc96093df",
   "metadata": {},
   "source": [
    "In this step, We build a Random Forest Classifier to predict. We will try to determine whether the banknote is fake or real from the features. We have two models for this step. The first one is Random Forest Classifier and the other is Random Forest Classifier with Gried Search.\n",
    "\n",
    "In both models, the accurrcy scores were very close. When the amount of errors is low, the effect of grid search does not show much.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40684402-7399-46f7-bce9-148d06da7150",
   "metadata": {},
   "source": [
    "#### Checking Random Forest Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5e5fe4-4d47-4ceb-bc8e-9494d7b8e9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = rf_grid.predict(X_train)\n",
    "y_pred = rf_grid.predict(X_test)\n",
    "rf_scores = {\"rf_train\": {\"accuracy\" : accuracy_score(y_train, y_train_pred),\n",
    "                          \"recall\"   : recall_score(y_train, y_train_pred),\n",
    "                          \"precision\": precision_score(y_train, y_train_pred),\n",
    "                          \"f1-score\" : f1_score(y_train, y_train_pred)} ,\n",
    "             \"rf_test\": {\"accuracy\" : accuracy_score(y_test, y_pred),\n",
    "                         \"recall\" : recall_score(y_test, y_pred),\n",
    "                         \"precision\" : precision_score(y_test, y_pred),\n",
    "                         \"f1-score\" : f1_score(y_test, y_pred)}}\n",
    "D_rf =pd.DataFrame(rf_scores)\n",
    "D_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550c7450-f08c-4998-9132-fadbc42c5ad7",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "* The model achieved perfect scores on the training set, indicating it learned the patterns in the training data very well.\n",
    "\n",
    "* The recall of 0.9885 on the test set suggests the model is effectively identifying nearly all positive cases.\n",
    "\n",
    "* The precision of 1.0 shows that all positive predictions made by the model were correct — there were no false positives.\n",
    "\n",
    "* The slight difference between training and test performance is minimal and acceptable, showing no significant overfitting.\n",
    "\n",
    "Conclusion:\n",
    "\n",
    "The tuned Random Forest model demonstrates excellent performance and strong generalization ability. It balances precision and recall effectively and achieves high predictive power with minimal overfitting. This makes it a reliable and robust classifier for the banknote authentication task.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adf31c5-313e-4b0f-ac94-2fd9c39cc3d7",
   "metadata": {},
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c51e644-f274-46d6-b655-34ffc56ecc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Random forest feature Importance\n",
    "feature_names = [\"Variance_Wavelet\", \"Skewness_Wavelet\", \"Curtosis_Wavelet\", \"Image_Entropy\"]  # Replace with the actual names\n",
    "feats = pd.DataFrame(index=feature_names, data=rf_model.feature_importances_, columns=[\"rf_importance\"])\n",
    "rf_imp_feats = feats.sort_values(\"rf_importance\", ascending=False)\n",
    "print(rf_imp_feats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811a7b89-e353-402f-84b9-823c2d0c7db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barplot for RandomForest Feature Importance\n",
    "sns.barplot(data=rf_imp_feats, x=rf_imp_feats.index, y='rf_importance')\n",
    "\n",
    "# Rotate x-axis labels\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()  # optional, to avoid label cutoff\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9dc8b9-f85e-4e6a-abda-277972c9736e",
   "metadata": {},
   "source": [
    "#### Plotting ROC Curves and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce138e4-d020-4fe9-ab90-3a87eab0ed23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted probabilities for the positive class\n",
    "y_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Compute FPR, TPR, and AUC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC Curve & AUC\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f\"Random Forest (AUC = {roc_auc:.2f})\", color=\"blue\")\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")  # Reference line\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve - Random Forest\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4a837c-e59c-41d1-ae69-030e28b751d6",
   "metadata": {},
   "source": [
    "Findings:\n",
    "\n",
    "ROC Curve: Shows how well the model separates classes at different thresholds.\n",
    "\n",
    "AUC (Area Under Curve):\n",
    "\n",
    "1.0 = perfect\n",
    "\n",
    "0.5 = random guess\n",
    "\n",
    "0.7–0.9 = good model\n",
    "\n",
    "This shows that Random forest is a perfect classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186e9e71-bede-461b-bc29-38913487a688",
   "metadata": {},
   "source": [
    "### 7.6 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd76ace4-9a27-4702-941b-f91c61d99863",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier(random_state = 42).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51981865-ff86-4f09-af86-73dc5a0f6adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Prediction on X_test\n",
    "xgb_y_pred = xgb_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20390da5-06fa-4c83-abe9-b234095c3fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking XGBoosting Accuracy score, Classification Report & Confusion Matrix before Tuning\n",
    "xgb_accuracy = accuracy_score(y_test, xgb_y_pred)\n",
    "xgb_conf_matrix = confusion_matrix(y_test, xgb_y_pred)\n",
    "xgb_report = classification_report(y_test, xgb_y_pred)\n",
    " \n",
    "# Output results, classification reports, and plot confusion matrix\n",
    "print(\"\\n=== XGB Boosting Results ===\")\n",
    "print(f\"Accuracy: {rt_accuracy:.2f}\")\n",
    "print(\"Classification Report on Test Set:\")\n",
    "print(classification_report(y_test, xgb_y_pred))\n",
    "\n",
    "# Plot confusion matrix\n",
    "fig, ax = plt.subplots()\n",
    "disp = ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test,\n",
    "    xgb_y_pred,\n",
    "    cmap='Blues',\n",
    "    ax=ax\n",
    ")\n",
    "disp.im_.colorbar.remove()  # Optional: remove color bar if you want an even cleaner look\n",
    "ax.grid(False)              # Turn off grid\n",
    "plt.title(\"Confusion Matrix - XGB Boosting\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96480738-e9a7-4533-a332-37463f030c02",
   "metadata": {},
   "source": [
    "#### Checking XGB Boosting Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3190611e-89b3-4f14-a782-a7b017b4f85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGB Boosting scores before Tuned with GridSearchCV\n",
    "y_train_pred = xgb_model.predict(X_train)\n",
    "xgb_y_pred = xgb_model.predict(X_test)\n",
    "xgb_scores = {\"xgb_train\": {\"accuracy\" : accuracy_score(y_train, y_train_pred),\n",
    "                          \"recall\"   : recall_score(y_train, y_train_pred),\n",
    "                          \"precision\": precision_score(y_train, y_train_pred),\n",
    "                          \"f1-score\" : f1_score(y_train, y_train_pred)} ,\n",
    "             \"xgb_test\": {\"accuracy\" : accuracy_score(y_test, y_pred),\n",
    "                         \"recall\" : recall_score(y_test, y_pred),\n",
    "                         \"precision\" : precision_score(y_test, y_pred),\n",
    "                         \"f1-score\" : f1_score(y_test, y_pred)}}\n",
    "D_xgb =pd.DataFrame(xgb_scores)\n",
    "D_xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea27896-b7f8-4ba9-b752-089ba4f3945a",
   "metadata": {},
   "source": [
    "#### XGB Boosting with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05739b13-414b-49ea-a83d-1eb9cf86a7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"n_estimators\" : [50,75], \"max_depth\" : [3, 4], \"learning_rate\": [0.01, 0.1],\n",
    "             \"subsample\": [0.5, 0.8], \"colsample_bytree\": [0.5, 0.7]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524bd0cb-806a-408f-96e0-5d5479cfd5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model_1 = XGBClassifier(random_state = 42)\n",
    "grid = GridSearchCV(xgb_model_1, param_grid, scoring = \"f1\", verbose=2,n_jobs =-1).fit(X_train, y_train)  # n_jobs -1 işlemciler son sürat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf439864-64cf-4b72-ae37-d3f1917dd3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69562d90-7922-46d5-9337-21134fe0df1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7fe69b-1d30-4b0b-bdb1-1d7f234af352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking XGB Boosting Accuracy score, Classification Report & Confusion Matrix after Tuning\n",
    "best_xgb = grid_search.best_estimator_\n",
    "\n",
    "# Predict on test data\n",
    "xgb_y_pred = best_xgb.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, xgb_y_pred)\n",
    "print(f\"Accuracy on Test Set: {accuracy:.4f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report on Test Set:\")\n",
    "print(classification_report(y_test, xgb_y_pred))\n",
    "\n",
    "# Plot confusion matrix\n",
    "fig, ax = plt.subplots()\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test,\n",
    "    xgb_y_pred,\n",
    "    cmap='Blues',\n",
    "    ax=ax\n",
    ")\n",
    "plt.title(\"Confusion Matrix - Tuned XGB Boosting\")\n",
    "plt.grid(False)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e81090-2bc2-4a09-a4c2-fed040ddd65f",
   "metadata": {},
   "source": [
    "#### Checking XGB Boosting Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27707062-473c-4f91-9b16-71ac5e8589b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGB Boosting scores after Tuned with GridSearchCV\n",
    "y_train_pred = grid.predict(X_train)\n",
    "y_pred = grid.predict(X_test)\n",
    "xgb_scores = {\"xgb_train\": {\"accuracy\" : accuracy_score(y_train, y_train_pred),\n",
    "                          \"recall\"   : recall_score(y_train, y_train_pred),\n",
    "                          \"precision\": precision_score(y_train, y_train_pred),\n",
    "                          \"f1-score\" : f1_score(y_train, y_train_pred)} ,\n",
    "             \"xgb_test\": {\"accuracy\" : accuracy_score(y_test, y_pred),\n",
    "                         \"recall\" : recall_score(y_test, y_pred),\n",
    "                         \"precision\" : precision_score(y_test, y_pred),\n",
    "                         \"f1-score\" : f1_score(y_test, y_pred)}}\n",
    "D_xgb =pd.DataFrame(xgb_scores)\n",
    "D_xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f56f89e-2043-4d3a-a3f5-1e195a9653e7",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "The XGBoost classifier achieved perfect performance on the training set and excellent performance on the test set, with 100% recall and 99.6% accuracy. The minimal gap between training and test metrics suggests that while the model fits the training data completely, it still generalizes extremely well. These results indicate that XGBoost is a highly effective model for this classification task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96927240-c201-460d-8b1c-6fb1fde02bd3",
   "metadata": {},
   "source": [
    "#### XGB Boosting Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7265f20a-62ec-4738-93f5-1df9819a10c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example if you know your features\n",
    "feature_names = [\"Variance_Wavelet\", \"Skewness_Wavelet\", \"Curtosis_Wavelet\", \"Image_Entropy\"]  # Replace with the actual names\n",
    "feats = pd.DataFrame(index=feature_names, data=xgb_model.feature_importances_, columns=[\"xgb_importance\"])\n",
    "xgb_imp_feats = feats.sort_values(\"xgb_importance\", ascending=False)\n",
    "print(xgb_imp_feats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ac0e5d-b5eb-4344-a751-5629e5b37399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barplot for XGB Boosting Feature Importance\n",
    "sns.barplot(data=xgb_imp_feats, x=xgb_imp_feats.index, y='xgb_importance')\n",
    "\n",
    "# Rotate x-axis labels\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()  # optional, to avoid label cutoff\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ada1af-4a63-44c1-8a0b-49ead29004f5",
   "metadata": {},
   "source": [
    "#### XGB Boosting ROC CurveS and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775b2cf1-148f-49ff-bd52-8fcbd39beb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities for the positive class\n",
    "y_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Compute ROC curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC Curve & AUC\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f\"XGBoost (AUC = {roc_auc:.2f})\", color=\"green\")\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve - XGBoost\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd80a0b-960f-437b-a945-a658b7731945",
   "metadata": {},
   "source": [
    "Findings:\n",
    "\n",
    "A higher AUC indicates that XGBoost is distinguishing between forged and authentic banknotes very effectively.\n",
    "\n",
    "Typical, AUC > 0.9 with XGBoost on clean, structured data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb30425-527a-41e7-9b5b-58164551c46a",
   "metadata": {},
   "source": [
    "### Comparison: \n",
    "\n",
    "* Decision Tree feature Importance\n",
    "\n",
    "* Random Forest Feature Importance\n",
    "\n",
    "* XGB Boosting Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2678ab1-dbce-4f8b-889b-0de49d5a442d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([dt_imp_feats, rf_imp_feats, xgb_imp_feats], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf63d35-0747-4c3c-867b-5ff33cdec92d",
   "metadata": {},
   "source": [
    "## 8. Model Comparison and Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4615c1f7-48ba-47a7-8bac-4a599d70b1ad",
   "metadata": {},
   "source": [
    "### 8.1 Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ca92b8-55ef-459f-9146-1e456319c616",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Your trained models dictionary\n",
    "models = {\n",
    "    \"Logistic Regression\": log_model,\n",
    "    \"SVM\": svc_model,\n",
    "    \"Decision Tree\": dt_model,\n",
    "    \"Random Forest\": rf_model,\n",
    "    \"KNN\": knn_model,\n",
    "    \"XGBoost\": xgb_model\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "# Loop through and evaluate each model\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Handle predict_proba safely\n",
    "    try:\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "        auc = roc_auc_score(y_test, y_proba)\n",
    "    except:\n",
    "        auc = None  # Some models like SVM without probability enabled\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred),\n",
    "        \"Recall\": recall_score(y_test, y_pred),\n",
    "        \"F1 Score\": f1_score(y_test, y_pred),\n",
    "        \"ROC AUC\": auc\n",
    "    })\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by=\"F1 Score\", ascending=False).reset_index(drop=True)\n",
    "results_df.style.background_gradient(cmap=\"YlGnBu\", subset=[\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"ROC AUC\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e6549d-32c8-47d9-827f-8da23c4dcb04",
   "metadata": {},
   "source": [
    "#### Key Observations\n",
    "\n",
    "SVM & KNN\n",
    "\n",
    "* Perfect scores across all metrics.\n",
    "\n",
    "* No misclassifications (no false positives or false negatives).\n",
    "\n",
    "* Extremely rare, and usually indicates:\n",
    "\n",
    "  A very easy classification task\n",
    "\n",
    "  Or possibly an overfitting issue if the test set is too small or too similar to the training set\n",
    "\n",
    "* These two should definitely be shortlisted.\n",
    "\n",
    "Logistic Regression & XGBoost\n",
    "\n",
    "* Very high scores, just a tiny dip in precision (0.989), but perfect recall and AUC.\n",
    "\n",
    "* These models also balance performance and interpretability (LogReg) or flexibility (XGBoost).\n",
    "\n",
    "* They show that even without tree-based tricks or kernels, the problem is still solvable with high confidence.\n",
    "\n",
    "Random Forest\n",
    "\n",
    "* Still great performance but slightly lower precision and F1.\n",
    "\n",
    "* AUC nearly perfect — 0.999 — so still highly separable.\n",
    "\n",
    "* Worth including in ensemble methods like VotingClassifier.\n",
    "\n",
    "Decision Tree\n",
    "    \n",
    "* The weakest among the models, with lowest metrics across the board.\n",
    "\n",
    "* No major flaws, but slightly less robust."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c820c1-839a-4377-bd0f-baf628c5df54",
   "metadata": {},
   "source": [
    "### 8.2 Overfitting Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d753c322-dd81-4008-9be4-0424a438ec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Try predict_proba (some models like SVM might not have it)\n",
    "    try:\n",
    "        y_train_proba = model.predict_proba(X_train)[:, 1]\n",
    "        y_test_proba = model.predict_proba(X_test)[:, 1]\n",
    "        auc_train = roc_auc_score(y_train, y_train_proba)\n",
    "        auc_test = roc_auc_score(y_test, y_test_proba)\n",
    "    except:\n",
    "        auc_train = None\n",
    "        auc_test = None\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Train Accuracy\": accuracy_score(y_train, y_train_pred),\n",
    "        \"Test Accuracy\": accuracy_score(y_test, y_test_pred),\n",
    "        \"F1 Score (Test)\": f1_score(y_test, y_test_pred),\n",
    "        \"ROC AUC (Train)\": auc_train,\n",
    "        \"ROC AUC (Test)\": auc_test\n",
    "    })\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by=\"F1 Score (Test)\", ascending=False).reset_index(drop=True)\n",
    "results_df.style.background_gradient(cmap=\"YlGnBu\", subset=[\"Train Accuracy\", \"Test Accuracy\", \"F1 Score (Test)\", \"ROC AUC (Test)\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f8747c-2e35-4951-a773-7c8ba0387930",
   "metadata": {},
   "source": [
    "Observation:\n",
    "\n",
    "Train ≈ Test\t✅ Model generalizes well\n",
    "\n",
    "Train ≫ Test\t🚨 Overfitting — model memorizing data\n",
    "\n",
    "Train ≪ Test\t🚨 Underfitting or data leakage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3332013b-4509-4d28-88a0-82e479de6c53",
   "metadata": {},
   "source": [
    "### 8.3 Visualize Model Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae57743-13fe-4d80-b67e-1621ddd0f4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update results_df if not yet done\n",
    "for i, (name, model) in enumerate(models.items()):\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    results_df.loc[results_df[\"Model\"] == name, \"Precision (Test)\"] = precision_score(y_test, y_test_pred)\n",
    "    results_df.loc[results_df[\"Model\"] == name, \"Recall (Test)\"] = recall_score(y_test, y_test_pred)\n",
    "\n",
    "# Define position for each metric\n",
    "bar_width = 0.15\n",
    "x = range(len(results_df))\n",
    "\n",
    "# Create figure\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "# Plot bars for each metric\n",
    "plt.bar([i for i in x], results_df[\"Test Accuracy\"], width=bar_width, label=\"Accuracy\", color=\"skyblue\")\n",
    "plt.bar([i + bar_width for i in x], results_df[\"Precision (Test)\"], width=bar_width, label=\"Precision\", color=\"plum\")\n",
    "plt.bar([i + 2 * bar_width for i in x], results_df[\"Recall (Test)\"], width=bar_width, label=\"Recall\", color=\"lightcoral\")\n",
    "plt.bar([i + 3 * bar_width for i in x], results_df[\"F1 Score (Test)\"], width=bar_width, label=\"F1 Score\", color=\"seagreen\")\n",
    "plt.bar([i + 4 * bar_width for i in x], results_df[\"ROC AUC (Test)\"], width=bar_width, label=\"ROC AUC\", color=\"orange\")\n",
    "\n",
    "# X-axis labels\n",
    "plt.xticks([i + 2 * bar_width for i in x], results_df[\"Model\"], rotation=45)\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0.9, 1.01)\n",
    "plt.title(\"Model Comparison: Accuracy, Precision, Recall, F1 Score, ROC AUC (Test Set)\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "plt.tight_layout()\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42b3011-437e-425b-b8b1-e230cb3c1444",
   "metadata": {},
   "source": [
    "### 8.4  Model Comparison Train and Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe741fd-8c61-4027-a928-a442eb717ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train vs Test Accuracy Plot\n",
    "plot_df = results_df.sort_values(by=\"Test Accuracy\", ascending=False)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(plot_df[\"Model\"], plot_df[\"Train Accuracy\"], marker='o', label=\"Train Accuracy\", color=\"green\")\n",
    "plt.plot(plot_df[\"Model\"], plot_df[\"Test Accuracy\"], marker='s', label=\"Test Accuracy\", color=\"blue\")\n",
    "\n",
    "# Formatting\n",
    "plt.title(\"Model Comparison: Train vs Test Accuracy\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.ylim(0.9, 1.01)\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae7c6b5-c691-4ea0-964b-e3ea90a77fd3",
   "metadata": {},
   "source": [
    "## 9. Hyperparameter Tuning (Top Models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb18a0ea-c495-4cdc-a46b-75971165d220",
   "metadata": {},
   "source": [
    "### 9.1 GridSearchCV for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d6a40e-7378-4292-ac47-b2c8d9a84c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Set up the GridSearchCV\n",
    "grid_svm = GridSearchCV(SVC(probability=True), param_grid_svm, cv=5, scoring='f1', n_jobs=-1)\n",
    "\n",
    "# Fit to training data\n",
    "grid_svm.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_svm = grid_svm.best_estimator_\n",
    "print(\"Best SVM Parameters:\", grid_svm.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8609d46c-fd0b-4eaf-b085-72b12fc8ded9",
   "metadata": {},
   "source": [
    "### 9.2 GridSearchCV for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6555bc2c-2851-4ddc-86a2-641adda48866",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "grid_knn = GridSearchCV(\n",
    "    estimator=KNeighborsClassifier(),\n",
    "    param_grid=param_grid_knn,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_knn.fit(X_train, y_train)\n",
    "\n",
    "# Already trained model\n",
    "best_knn = grid_knn.best_estimator_\n",
    "print(\"Best KNN Parameters:\", grid_knn.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2020f078-8f23-4683-a77c-b12ad70d707e",
   "metadata": {},
   "source": [
    "### 9.3 GridSearchCV for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89187545-0b6e-459c-9a15-f9f434bef9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    param_grid_rf,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "# This model is already trained and ready to use\n",
    "best_rf = grid_rf.best_estimator_\n",
    "print(\"Best RF Parameters:\", grid_rf.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14b3600-7289-4ea6-9f9a-a8f237247896",
   "metadata": {},
   "source": [
    "### 9.4 GridSearchCV for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0409dcfa-d468-4ef7-8191-3c3f5bdf57e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# You can comment this out if you're not using it\n",
    "# xgb = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Define and fit manually tuned model\n",
    "best_xgb = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42\n",
    ")\n",
    "best_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Double-check that it's the correct type\n",
    "print(\"Type of best_xgb:\", type(best_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e7fab6-a72e-4c18-9b92-0354231bd0c1",
   "metadata": {},
   "source": [
    "## 10. Ensemble Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754fa60e-1952-44c0-895d-e1ae6d153b6d",
   "metadata": {},
   "source": [
    "### 10.1 VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f295c8b-4da0-41a6-a3fe-0c49e480a706",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Create base models (make sure these are properly instantiated)\n",
    "best_svm = SVC(probability=True, random_state=42)\n",
    "best_knn = KNeighborsClassifier()\n",
    "best_rf = RandomForestClassifier(random_state=42)\n",
    "best_xgb = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Optionally fit each base model\n",
    "best_svm.fit(X_train, y_train)\n",
    "best_knn.fit(X_train, y_train)\n",
    "best_rf.fit(X_train, y_train)\n",
    "best_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Create voting ensemble\n",
    "voting_model = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('svm', best_svm),\n",
    "        ('knn', best_knn),\n",
    "        ('rf', best_rf),\n",
    "        ('xgb', best_xgb)\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# Fit voting model on data\n",
    "voting_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9454265a-5459-4ecf-aec6-fca212a37463",
   "metadata": {},
   "source": [
    "### 10.2 Evaluation of Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2646caf3-1edd-4310-af5d-98d20f0b21ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating Voting Model\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred_vote = voting_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_vote))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c274a44-983a-4b86-b8a0-e91a9c62faac",
   "metadata": {},
   "source": [
    "### 10.3 Confusion Matrix and ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644ea7a4-cbad-4c8e-80ec-7d902bc871fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Confusion Matrix for Top Models\n",
    "from sklearn.metrics import confusion_matrix\n",
    "def plot_confusion_matrix(model, X, y, title=\"Confusion Matrix\"):\n",
    "    # Predict\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    # Get confusion matrix\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                xticklabels=['Genuine (0)', 'Forged (1)'],\n",
    "                yticklabels=['Genuine (0)', 'Forged (1)'])\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(best_svm, X_test, y_test, \"Confusion Matrix - SVM\")\n",
    "plot_confusion_matrix(best_knn, X_test, y_test, \"Confusion Matrix - KNN\")\n",
    "plot_confusion_matrix(best_rf, X_test, y_test, \"Confusion Matrix - Random Forest\")\n",
    "plot_confusion_matrix(best_xgb, X_test, y_test, \"Confusion Matrix - XGBoost\")\n",
    "plot_confusion_matrix(voting_model, X_test, y_test, \"Confusion Matrix - Voting Classifier\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4a29f1-7197-4cd4-8a3a-591145a4570d",
   "metadata": {},
   "source": [
    "### ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd22991-fb17-4fc9-ab3c-6ef63bd5634f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def plot_roc_curves(models_dict, X_test, y_test):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for name, model in models_dict.items():\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f\"{name} (AUC = {roc_auc:.2f})\")\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Random Chance')\n",
    "    plt.title(\"ROC Curve Comparison\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show();\n",
    "\n",
    "# Run it\n",
    "plot_roc_curves({\n",
    "    \"SVM\": best_svm,\n",
    "    \"KNN\": best_knn,\n",
    "    \"RF\": best_rf,\n",
    "    \"XGB\": best_xgb,\n",
    "    \"Voting\": voting_model\n",
    "}, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6ce743-569e-4573-a8a6-955e1cdbd004",
   "metadata": {},
   "source": [
    "Observation:\n",
    "\n",
    "The models are perfectly separating the classes (genuine vs forged) on the test set.\n",
    "\n",
    "No overlap between predicted probabilities of Class 0 and Class 1.\n",
    "\n",
    "True Positive Rate (Recall) is 100% at all thresholds.\n",
    "\n",
    "False Positive Rate is 0 — incredible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7d6d23-64b4-47c2-9bfe-27196b1cfd6e",
   "metadata": {},
   "source": [
    "## 11. Save Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089e44b7-1591-4aa3-ae65-557abc49a37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "\n",
    "# Make sure the models directory exists\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(voting_model, \"models/best_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41031760-8455-4168-a7b5-9bf3a87fdf32",
   "metadata": {},
   "source": [
    "### 11.1 Save Scaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d3b129-7b01-4a67-bada-e1870d435310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the scaler:\n",
    "joblib.dump(scaler, \"models/scaler.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1ed340-f4ed-4c7d-956a-24370273047f",
   "metadata": {},
   "source": [
    "### 11.2 Load Saved Trained Model and Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e013d1b-52e4-4416-9acc-5bfb7cb3ed76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = joblib.load(\"models/best_model.pkl\")\n",
    "\n",
    "# Assuming you have new sample data in the same format as your training features (i.e., 4 features):\n",
    "new_sample = [[2.3, 6.7, -1.3, 0.5]]  # variance, skewness, curtosis, entropy\n",
    "\n",
    "scaler = joblib.load(\"models/scaler.pkl\")\n",
    "model = joblib.load(\"models/best_model.pkl\")\n",
    "\n",
    "scaled_sample = scaler.transform(new_sample)\n",
    "\n",
    "# Predict class\n",
    "prediction = model.predict(scaled_sample)\n",
    "\n",
    "# Output result\n",
    "print(\"Prediction:\", \"Authentic\" if prediction[0] == 0 else \"Forged\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c305945-17b8-4972-8460-9290d025bceb",
   "metadata": {},
   "source": [
    "## 12. Deployment (Optional)\n",
    "\n",
    "To demonstrate practical deployment, I have developed and deployed a cloud-based web application for the banknote authentication model using Streamlit and Gradio. The application allows users to input feature values and receive real-time predictions on the authenticity of banknotes.\n",
    "\n",
    "This interactive tool was created for educational purposes and hands-on machine learning practice.\n",
    "\n",
    "You can access the application here for Streamlit: [Banknote Authentication App]\n",
    "\n",
    "You can access the application here for Gradio: [Banknote Authentication App]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defa77ff-17de-41bd-8399-bf6db511979b",
   "metadata": {},
   "source": [
    "## 13. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acd4dd0-1a41-48c5-a1e3-6cd93b9ced74",
   "metadata": {},
   "source": [
    "### Conclusion: Final Model Ranking and Recommendation\n",
    "\n",
    "After training and evaluating multiple classification models on the Banknote Authentication dataset, I compared their performance using key metrics: Accuracy, Precision, Recall, F1 Score, and ROC AUC. All models achieved a perfect ROC AUC of 1.00, indicating excellent separation between genuine and forged banknotes.\n",
    "\n",
    "To identify the most reliable models, I prioritized the F1 Score — the harmonic mean of precision and recall — which is crucial when both false positives and false negatives carry risk.\n",
    "\n",
    "#### Top 3 Models (Based on F1 Score and Stability)\n",
    "\n",
    "| Model            | F1 Score | Precision | Recall | ROC AUC |\n",
    "| ---------------- | -------- | --------- | ------ | ------- |\n",
    "| SVM              | 0.994    | 0.989     | 1.000  | 1.000   |\n",
    "| KNN              | 0.994    | 0.989     | 1.000  | 1.000   |\n",
    "| VotingClassifier | 0.994    | 0.989     | 1.000  | 1.000   |\n",
    "\n",
    "The VotingClassifier, which combines the predictions of SVM, KNN, Random Forest, and XGBoost using soft voting, matched the performance of the top individual models and offers enhanced robustness through ensemble learning.\n",
    "\n",
    "#### Recommendation\n",
    "\n",
    "* Use the VotingClassifier for final deployment — it leverages multiple strong learners and delivers stable, highly accurate results.\n",
    "\n",
    "* If computational efficiency is a concern, SVM or KNN can serve as strong standalone alternatives.\n",
    "\n",
    "* No overfitting was observed based on train/test splits and cross-validation.\n",
    "\n",
    "* All preprocessing steps were applied after the train-test split to avoid target leakage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd6f703-84f0-43d7-bdba-add3b15619c1",
   "metadata": {},
   "source": [
    "###  Project Summary\n",
    "\n",
    "* Dataset: UCI Banknote Authentication (1,372 instances, 4 features)\n",
    "\n",
    "* Goal: Predict whether a banknote is authentic (0) or forged (1) using statistical image features.\n",
    "\n",
    "* Models Evaluated: Logistic Regression, SVM, KNN, Random Forest, XGBoost, Decision Tree\n",
    "\n",
    "* Top Performers: SVM, KNN, VotingClassifier\n",
    "\n",
    "* Tech Stack: Python, Scikit-learn, XGBoost, Pandas, Seaborn, Matplotlib\n",
    "\n",
    "Key Features:\n",
    "\n",
    "* Extracted using Wavelet Transform:\n",
    "\n",
    "Variance, Skewness, Curtosis, Entropy\n",
    "\n",
    "* All features are continuous with no missing values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5d94fa-5bdd-4095-a192-205b666339d4",
   "metadata": {},
   "source": [
    "## 14. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823713df-94ff-47b7-afd6-960930c0e8e2",
   "metadata": {},
   "source": [
    "The VotingClassifier achieved the best overall results:\n",
    "\n",
    "* F1 Score: 0.994\n",
    "\n",
    "* ROC AUC: 1.00\n",
    "\n",
    "* Recall: 1.00 (No false negatives)\n",
    "\n",
    "##### This ensemble model is robust, interpretable, and ready for deployment in real-world banknote authentication systems.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad533eaf-3a42-47ef-afde-032a03c5a71e",
   "metadata": {},
   "source": [
    "## 15. References\n",
    "\n",
    "### Books & Courses\n",
    "\n",
    "1. Huyen, C. (2022). Designing Machine Learning Systems: An Iterative Process for Production-Ready Applications. O'Reilly Media.\n",
    "\n",
    "A practical guide for building real-world machine learning systems with a focus on deployment and scalability.\n",
    "\n",
    "2. Géron, A. (2019). Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow (2nd ed.). O'Reilly Media.\n",
    "\n",
    "A hands-on guide to building machine learning and deep learning systems using Python.\n",
    "\n",
    "3. Ng, A. (2022). Machine Learning Specialization. DeepLearning.AI / Stanford University on Coursera.\n",
    "\n",
    "A foundational program on machine learning theory and applications.\n",
    "\n",
    "### Tools & Libraries\n",
    "\n",
    "4. Pedregosa, F., Varoquaux, G., Gramfort, A., et al. (2011). Scikit-learn: Machine Learning in Python. Journal of Machine Learning Research, 12, 2825–2830.\n",
    "\n",
    "https://scikit-learn.org\n",
    "\n",
    "5. Chen, T., & Guestrin, C. (2016). XGBoost: A Scalable Tree Boosting System. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.\n",
    "\n",
    "https://xgboost.ai\n",
    "\n",
    "6. Abid, A., et al. (2021). Gradio: Hassle-Free Sharing and Testing of ML Models.\n",
    "\n",
    "https://gradio.app\n",
    "\n",
    "7. Streamlit Inc. (2021). Streamlit: The fastest way to build data apps.\n",
    "\n",
    "https://streamlit.io\n",
    "\n",
    "8. Van Rossum, G., & Drake, F. L. (2009). Python 3 Reference Manual. CreateSpace.\n",
    "\n",
    "https://www.python.org\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d7234f-9a1f-4ac7-80b4-6ea11bcda45d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd6deaf-8280-427e-8ae5-7f37ca87a22f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf773e7a-ac22-444d-9d8f-74f7917aadc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1e8763-d905-41fa-af17-7ed0902f589c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef60bae-70d3-4040-a1d8-797adc774f95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f33137-86c1-44a1-a452-2035c1487a30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b541999a-4815-46ab-b495-ea1938eac07c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c16cde-43bf-41d8-a707-8d7b969e7f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d4d659-9e21-46ab-8f42-017245243e72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d0cc74-6716-4706-a809-1950e0873f20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
